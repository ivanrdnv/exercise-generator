{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#experiments\" data-toc-modified-id=\"experiments-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>experiments</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill in the missing word with choices\n",
    "2. Sentence structure\n",
    "3. Choose the correct sentence\n",
    "4. Missing words, parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***pyinflect's Tags***\n",
    "\n",
    "pos_type = 'A'\n",
    "* JJ      Adjective\n",
    "* JJR     Adjective, comparative\n",
    "* JJS     Adjective, superlative\n",
    "* RB      Adverb\n",
    "* RBR     Adverb, comparative\n",
    "* RBS     Adverb, superlative\n",
    "\n",
    "pos_type = 'N'\n",
    "* NN      Noun, singular or mass\n",
    "* NNS     Noun, plural\n",
    "\n",
    "pos_type = 'V'\n",
    "* VB      Verb, base form\n",
    "* VBD     Verb, past tense\n",
    "* VBG     Verb, gerund or present participle\n",
    "* VBN     Verb, past participle\n",
    "* VBP     Verb, non-3rd person singular present\n",
    "* VBZ     Verb, 3rd person singular present\n",
    "* MD      Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "import pathlib\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "from pyinflect import getAllInflections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(text):\n",
    "    splitter = SentenceSplitter(language='en')\n",
    "    sentences = splitter.split(text)\n",
    "    df = pd.DataFrame(sentences, columns=['raw'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_word(sentence):\n",
    "    \"\"\"\n",
    "    Selects a word from a given sentence and returns a list of possible inflected forms.\n",
    "    Args: sentence (str). Returns: a list of inflected word forms. \n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    candidate_tokens = [token for token in doc if not token.is_punct and not token.is_space\n",
    "                            and token.is_lower and token.tag_.startswith(('V', 'N'))] # , 'A'\n",
    "    if not candidate_tokens:\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    selected_word = random.choice(candidate_tokens)\n",
    "    inflections = getAllInflections(selected_word.lemma_, pos_type=selected_word.tag_[0])\n",
    "\n",
    "    unique_values = [selected_word.lower_]\n",
    "\n",
    "    # add the plural form for checking user's knowledge of noun pluralization\n",
    "    if selected_word.pos_.startswith('N'):\n",
    "        s_form = selected_word.lemma_ + 's'\n",
    "        if s_form not in unique_values:\n",
    "            unique_values.append(s_form)\n",
    "\n",
    "    for forms in inflections.values():\n",
    "        for form in forms:\n",
    "            if form not in unique_values:\n",
    "                unique_values.append(form)\n",
    "\n",
    "    while len(unique_values) > 4:\n",
    "        unique_values.pop()\n",
    "\n",
    "    random.shuffle(unique_values)\n",
    "    return selected_word, unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Little_Red_Cap_ Jacob_and_Wilhelm_Grimm.txt\"\n",
    "\n",
    "# Read the text from the file\n",
    "text = pathlib.Path(file_name).read_text(encoding='utf-8')\n",
    "basic_english = pd.read_csv('ogden_basic_english.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogden_basic_english = basic_english['0'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = text_to_sentences(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = 'select_word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mars/opt/anaconda3/envs/da_practicum/lib/python3.9/site-packages/pandas/core/common.py:208: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "df['object'], df['options'] = zip(*df['raw'].apply(select_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_word(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    candidate_tokens = [token for token in doc if not token.is_punct and not token.is_space\n",
    "                            and token.is_lower and token.lemma_ in ogden_basic_english]\n",
    "    if not candidate_tokens:\n",
    "        return np.nan\n",
    "    \n",
    "    selected_word = random.choice(candidate_tokens)\n",
    "    return selected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "def generate_incorrect_variations(sentence):\n",
    "    # Load the pre-trained DistilBERT model and tokenizer\n",
    "    model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Tokenize the sentence\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "    # Generate multiple completions using the DistilBERT model\n",
    "    outputs = model.generate(input_ids, max_length=100, num_return_sequences=4, num_beams=5)\n",
    "\n",
    "    # Decode the generated sequences into sentences\n",
    "    variations = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "    return variations\n",
    "\n",
    "# Example usage\n",
    "initial_sentence = \"Do you like broccoli?\"\n",
    "incorrect_variations = generate_incorrect_variations(initial_sentence)\n",
    "print(incorrect_variations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_incorrect_variations('She decided to eat that cake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
